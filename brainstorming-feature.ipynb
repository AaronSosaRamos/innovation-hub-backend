{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain_community langchain_openai langchain_experimental neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" \n",
    "Large Language Models (LLMs), such as GPT-4 and the PaLM architecture, represent a significant leap in the domain of natural language processing (NLP) due to their transformative use of deep learning techniques, particularly transformer-based architectures. These models rely on an extensive number of parameters, often reaching into the hundreds of billions, to encode semantic relationships across vast corpora. By leveraging self-attention mechanisms, LLMs excel at capturing long-range dependencies and contextual relationships within text, enabling them to generate syntactically coherent and semantically rich responses. The pre-training phase involves unsupervised learning across a wide variety of domains, after which models are fine-tuned on downstream tasks using supervised or reinforcement learning techniques. However, despite their performance, the interpretability of such models remains limited, as they function largely as black-box systems, leading to ongoing research into explainable AI (XAI) within this subfield.\n",
    "\n",
    "In addition to their proficiency in standard NLP tasks, LLMs are increasingly integrated into sophisticated multimodal systems, which allow them to process and generate data across diverse formats, including images, audio, and even video. Recent advances in retrieval-augmented generation (RAG) enable LLMs to interface with structured external knowledge bases, thus overcoming the limitations of purely parametric knowledge storage and mitigating hallucination issues by grounding output in verifiable data. Despite these advances, challenges persist, particularly in terms of mitigating issues like model bias, ensuring factual accuracy in generated outputs, and addressing the computational inefficiencies of training and inference in large-scale transformer models. These remain critical research areas as the field progresses toward more robust, scalable, and interpretable LLM architectures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content = text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='Large Language Models' type='Concept' properties={}\n",
      "id='Gpt-4' type='Model' properties={}\n",
      "id='Palm Architecture' type='Model' properties={}\n",
      "id='Natural Language Processing' type='Field' properties={}\n",
      "id='Deep Learning Techniques' type='Concept' properties={}\n",
      "id='Transformer-Based Architectures' type='Concept' properties={}\n",
      "id='Parameters' type='Concept' properties={}\n",
      "id='Self-Attention Mechanisms' type='Concept' properties={}\n",
      "id='Pre-Training Phase' type='Concept' properties={}\n",
      "id='Unsupervised Learning' type='Concept' properties={}\n",
      "id='Downstream Tasks' type='Concept' properties={}\n",
      "id='Supervised Learning' type='Concept' properties={}\n",
      "id='Reinforcement Learning' type='Concept' properties={}\n",
      "id='Interpretability' type='Concept' properties={}\n",
      "id='Black-Box Systems' type='Concept' properties={}\n",
      "id='Explainable Ai' type='Concept' properties={}\n",
      "id='Multimodal Systems' type='Concept' properties={}\n",
      "id='Retrieval-Augmented Generation' type='Concept' properties={}\n",
      "id='Structured External Knowledge Bases' type='Concept' properties={}\n",
      "id='Model Bias' type='Concept' properties={}\n",
      "id='Factual Accuracy' type='Concept' properties={}\n",
      "id='Computational Inefficiencies' type='Concept' properties={}\n",
      "id='Large-Scale Transformer Models' type='Concept' properties={}\n"
     ]
    }
   ],
   "source": [
    "for node in graph_documents[0].nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Natural Language Processing', type='Field', properties={}) type='RELATED_TO' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Deep Learning Techniques', type='Concept', properties={}) type='USES' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Transformer-Based Architectures', type='Concept', properties={}) type='USES' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Parameters', type='Concept', properties={}) type='RELIES_ON' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Self-Attention Mechanisms', type='Concept', properties={}) type='USES' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Pre-Training Phase', type='Concept', properties={}) type='INVOLVES' properties={}\n",
      "source=Node(id='Pre-Training Phase', type='Concept', properties={}) target=Node(id='Unsupervised Learning', type='Concept', properties={}) type='INVOLVES' properties={}\n",
      "source=Node(id='Pre-Training Phase', type='Concept', properties={}) target=Node(id='Downstream Tasks', type='Concept', properties={}) type='FINE-TUNED_ON' properties={}\n",
      "source=Node(id='Downstream Tasks', type='Concept', properties={}) target=Node(id='Supervised Learning', type='Concept', properties={}) type='USES' properties={}\n",
      "source=Node(id='Downstream Tasks', type='Concept', properties={}) target=Node(id='Reinforcement Learning', type='Concept', properties={}) type='USES' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Interpretability', type='Concept', properties={}) type='HAS_LIMITATION' properties={}\n",
      "source=Node(id='Interpretability', type='Concept', properties={}) target=Node(id='Black-Box Systems', type='Concept', properties={}) type='RELATED_TO' properties={}\n",
      "source=Node(id='Interpretability', type='Concept', properties={}) target=Node(id='Explainable Ai', type='Concept', properties={}) type='RESEARCH_AREA' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Multimodal Systems', type='Concept', properties={}) type='INTEGRATED_INTO' properties={}\n",
      "source=Node(id='Large Language Models', type='Concept', properties={}) target=Node(id='Retrieval-Augmented Generation', type='Concept', properties={}) type='ENABLES' properties={}\n",
      "source=Node(id='Retrieval-Augmented Generation', type='Concept', properties={}) target=Node(id='Structured External Knowledge Bases', type='Concept', properties={}) type='INTERFACES_WITH' properties={}\n",
      "source=Node(id='Retrieval-Augmented Generation', type='Concept', properties={}) target=Node(id='Model Bias', type='Concept', properties={}) type='MITIGATES_ISSUES_LIKE' properties={}\n",
      "source=Node(id='Retrieval-Augmented Generation', type='Concept', properties={}) target=Node(id='Factual Accuracy', type='Concept', properties={}) type='ENSURES' properties={}\n",
      "source=Node(id='Retrieval-Augmented Generation', type='Concept', properties={}) target=Node(id='Computational Inefficiencies', type='Concept', properties={}) type='ADDRESSES' properties={}\n"
     ]
    }
   ],
   "source": [
    "for relationship in graph_documents[0].relationships:\n",
    "    print(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents=graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Additional suggestions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_transformer_filtered = LLMGraphTransformer(\n",
    "#     llm=llm,\n",
    "#     allowed_nodes=[...],\n",
    "#     allowed_relationships=[\"...\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "#     documents\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for node in graph_documents_filtered[0].nodes:\n",
    "#     print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for relationship in graph_documents_filtered[0].relationships:\n",
    "#     print(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.add_graph_documents(graph_documents_filtered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
